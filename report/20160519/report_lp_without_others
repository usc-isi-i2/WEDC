
because there are 15 out of 118 posts do not contain any seed words
if these posts are used to train LP classifier, could influce the result, especially when 2 or more posts in different categories and meanwhile they do not contain any seed words.


#############################################################
 Test: 1
#############################################################
training size: 11
training_labels: [2, 4, 4, 4, 3, 3, 3, 3, 4, 4, 3]
training_index: [13, 23, 27, 28, 44, 67, 77, 91, 99, 101, 109]
+--------------------------------------------------------+
|                         Report                         |
+--------------------------------------------------------+
predict label:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 4, 3, 4, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 3, 4, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4, 4, 3, 3, 4, 2, 2, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 3, 2, 2, 3, 2, 3, 3, 2, 3, 4, 3, 2, 2, 4, 3, 2, 2, 3, 4, 4, 4]
y_test:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
             precision    recall  f1-score   support

          2       0.32      1.00      0.48        19
          3       0.97      0.50      0.66        62
          4       0.53      0.31      0.39        26

avg / total       0.75      0.54      0.56       107

accuracy: 0.542056074766

#############################################################
 Test: 2
#############################################################
training size: 11
training_labels: [2, 4, 4, 4, 3, 4, 4, 3, 3, 3, 3]
training_index: [5, 22, 29, 33, 36, 40, 41, 44, 47, 48, 98]
+--------------------------------------------------------+
|                         Report                         |
+--------------------------------------------------------+
predict label:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 4, 4, 2, 4, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 2, 4, 4, 3, 3, 4, 2, 2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 4, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 3, 4, 3, 2, 4, 2, 4, 3, 2, 2, 3, 4, 4, 4]
y_test:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
             precision    recall  f1-score   support

          2       0.33      1.00      0.50        19
          3       1.00      0.45      0.62        62
          4       0.45      0.38      0.42        26

avg / total       0.75      0.53      0.55       107

accuracy: 0.532710280374


#############################################################
 Test: 3
#############################################################
training size: 11
training_labels: [2, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3]
training_index: [9, 23, 41, 42, 48, 57, 62, 76, 83, 94, 114]
+--------------------------------------------------------+
|                         Report                         |
+--------------------------------------------------------+
predict label:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 3, 4, 3, 2, 3, 2, 4, 3, 3, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3]
y_test:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
             precision    recall  f1-score   support

          2       0.36      1.00      0.53        19
          3       0.86      0.75      0.80        59
          4       1.00      0.10      0.19        29

avg / total       0.81      0.62      0.59       107

accuracy: 0.616822429907



#############################################################
 Test: 4
#############################################################

training size: 11
training_labels: [2, 2, 2, 2, 4, 4, 4, 3, 3, 3, 3]
training_index: [8, 13, 17, 20, 22, 26, 45, 62, 70, 74, 106]
+--------------------------------------------------------+
|                         Report                         |
+--------------------------------------------------------+
predict label:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 4, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 3, 3, 3]
y_test:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
             precision    recall  f1-score   support

          2       0.27      1.00      0.42        16
          3       0.85      0.62      0.72        63
          4       1.00      0.04      0.07        28

avg / total       0.80      0.52      0.50       107

accuracy: 0.523364485981


#############################################################
 Test: 5
#############################################################


training size: 11
training_labels: [2, 4, 4, 3, 3, 3, 4, 3, 4, 3, 4]
training_index: [7, 30, 37, 51, 55, 67, 69, 71, 84, 95, 99]
+--------------------------------------------------------+
|                         Report                         |
+--------------------------------------------------------+
predict label:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 3, 2, 2, 2, 3, 4, 2, 3, 4, 2, 2, 2, 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 4, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 2, 2, 2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 4, 2, 2, 2, 3, 3, 2, 3, 3, 2, 3, 4, 3, 2, 4, 2, 4, 3, 2, 2, 3, 4, 4, 4]
y_test:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
             precision    recall  f1-score   support

          2       0.34      1.00      0.51        19
          3       0.94      0.52      0.67        62
          4       0.47      0.31      0.37        26

avg / total       0.72      0.55      0.57       107

accuracy: 0.551401869159
